{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:06:10.511529: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-16 20:06:10.545511: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-16 20:06:10.545541: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-16 20:06:10.545565: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-16 20:06:10.552017: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from seismic_purifier import RepresentationLearningSingleAutoencoder, RepresentationLearningDenoisingSingleAutoencoder, RepresentationLearningMultipleAutoencoder\n",
    "from kfold_trainer import KfoldTrainer\n",
    "from config import KFOLD_SPLITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment name.\n",
    "EXP_NAME = \"exp_test\"\n",
    "\n",
    "# Should be one of the RepresentationLearningSingleAutoencoder, RepresentationLearningDenoisingSingleAutoencoder, RepresentationLearningMultipleAutoencoder\n",
    "MODEL_CLASSES = [RepresentationLearningSingleAutoencoder, RepresentationLearningDenoisingSingleAutoencoder, RepresentationLearningMultipleAutoencoder]\n",
    "\n",
    "# Should be stead,instance or raw.\n",
    "DATASETS = [\"raw\"]\n",
    "\n",
    "# Number of epochs\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:06:47.723849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20267 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:19:00.0, compute capability: 8.6\n",
      "2025-03-16 20:06:47.724859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 20267 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1a:00.0, compute capability: 8.6\n",
      "2025-03-16 20:06:47.725744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 20267 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:67:00.0, compute capability: 8.6\n",
      "2025-03-16 20:06:47.727421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 20251 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 273 mseed files to process.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(KFOLD_SPLITS):\n\u001b[1;32m      5\u001b[0m     kfold_trainer \u001b[38;5;241m=\u001b[39m KfoldTrainer(\n\u001b[1;32m      6\u001b[0m         EXP_NAME, model_class, train_dataset, split, epochs\u001b[38;5;241m=\u001b[39mNUM_EPOCHS\n\u001b[1;32m      7\u001b[0m     )\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mkfold_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rawcovar/reproducibility/kfold_trainer.py:58\u001b[0m, in \u001b[0;36mKfoldTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     48\u001b[0m ):\n\u001b[1;32m     49\u001b[0m     kfold_env \u001b[38;5;241m=\u001b[39m KFoldEnvironment(\n\u001b[1;32m     50\u001b[0m         dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset,\n\u001b[1;32m     51\u001b[0m     )\n\u001b[1;32m     53\u001b[0m     (\n\u001b[1;32m     54\u001b[0m         train_gen,\n\u001b[1;32m     55\u001b[0m         validation_gen,\n\u001b[1;32m     56\u001b[0m         __,\n\u001b[1;32m     57\u001b[0m         __,\n\u001b[0;32m---> 58\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43mkfold_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_generators\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     makedirs(\n\u001b[1;32m     61\u001b[0m         get_checkpoint_dir(\n\u001b[1;32m     62\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexp_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit\n\u001b[1;32m     63\u001b[0m         ),\n\u001b[1;32m     64\u001b[0m         exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     65\u001b[0m     )\n\u001b[1;32m     67\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model()\n",
      "File \u001b[0;32m~/rawcovar/reproducibility/kfold_environment.py:256\u001b[0m, in \u001b[0;36mKFoldEnvironment.get_generators\u001b[0;34m(self, split)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;124;03mReturns the training generator for a specific split.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03m    The training generator.\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# Get datagenerator objects.\u001b[39;00m\n\u001b[0;32m--> 256\u001b[0m train_datagen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_datagen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_splits\u001b[49m\u001b[43m[\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m validation_datagen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_datagen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_splits[split])\n\u001b[1;32m    258\u001b[0m test_datagen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_datagen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_splits[split])\n",
      "File \u001b[0;32m~/rawcovar/reproducibility/kfold_environment.py:639\u001b[0m, in \u001b[0;36mKFoldEnvironment._get_datagen\u001b[0;34m(self, active_chunks)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# Creates the path of the preprocessed dataset.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m processed_hdf5_path \u001b[38;5;241m=\u001b[39m join(\n\u001b[1;32m    634\u001b[0m     processed_hdf5_dir,\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubsampled_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124mpercent.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubsampling_factor)),\n\u001b[1;32m    636\u001b[0m )\n\u001b[1;32m    638\u001b[0m common_params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m--> 639\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed_hdf5_path\u001b[39m\u001b[38;5;124m'\u001b[39m: processed_hdf5_path,\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchunk_metadata_list\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_metadata_list,\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset_time_window\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_time_window,\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_time_window\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_time_window,\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphase_ensured_crop_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphase_ensured_crop_ratio,\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast_axis\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_axis,\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msampling_freq\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_freq,\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactive_chunks\u001b[39m\u001b[38;5;124m'\u001b[39m: active_chunks,\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfreqmin\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfreqmin,\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfreqmax\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfreqmax,\n\u001b[1;32m    650\u001b[0m }\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    653\u001b[0m     common_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_hdf5_path\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_hdf5_path\n",
      "File \u001b[0;32m~/rawcovar/reproducibility/data_generator.py:432\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, processed_hdf5_path, chunk_metadata_list, batch_size, phase_ensured_crop_ratio, dataset_time_window, model_time_window, sampling_freq, active_chunks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDataGenerator\u001b[39;00m(Sequence):\n\u001b[1;32m    405\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;124;03m    DataGenerator is a class that generates batches of data for training, validation\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;124;03m    and testing. It is used by TrainingGenerator, ValidationGenerator and TestGenerator\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;124;03m        last_axis (str): The last axis of the data. Can be either \"channels\" or \"timesteps\".\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m--> 432\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    433\u001b[0m         processed_hdf5_path,\n\u001b[1;32m    434\u001b[0m         chunk_metadata_list,\n\u001b[1;32m    435\u001b[0m         batch_size,\n\u001b[1;32m    436\u001b[0m         phase_ensured_crop_ratio,\n\u001b[1;32m    437\u001b[0m         dataset_time_window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m120.0\u001b[39m,\n\u001b[1;32m    438\u001b[0m         model_time_window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30.0\u001b[39m,\n\u001b[1;32m    439\u001b[0m         sampling_freq\u001b[38;5;241m=\u001b[39mSAMPLING_FREQ,\n\u001b[1;32m    440\u001b[0m         active_chunks\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m    441\u001b[0m         eq_hdf5_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    442\u001b[0m         no_hdf5_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    443\u001b[0m         raw_hdf5_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    444\u001b[0m         last_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannels\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    445\u001b[0m         freqmin\u001b[38;5;241m=\u001b[39mFREQMIN,\n\u001b[1;32m    446\u001b[0m         freqmax\u001b[38;5;241m=\u001b[39mFREQMAX,\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    448\u001b[0m     ):\n\u001b[1;32m    449\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_hdf5_path \u001b[38;5;241m=\u001b[39m processed_hdf5_path\n\u001b[1;32m    450\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_metadata_list \u001b[38;5;241m=\u001b[39m chunk_metadata_list\n",
      "File \u001b[0;32m~/rawcovar/reproducibility/data_generator.py:516\u001b[0m, in \u001b[0;36m_render_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_chunk_idx_and_batch_offset\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch_idx):\n\u001b[1;32m    514\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m \u001b[38;5;124;03m        batch_idx (int): Index of the batch.\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \n\u001b[1;32m    518\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;124;03m        tuple: A tuple of (chunk, batch_offset). chunk is the chunk that the batch belongs to\u001b[39;00m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;124;03m            and batch_offset is the offset of the batch in the chunk.\u001b[39;00m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    522\u001b[0m     batch_offset \u001b[38;5;241m=\u001b[39m batch_idx\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactive_chunks:\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# For all splits, train the model over defined datasets.\n",
    "for train_dataset in DATASETS:\n",
    "    for model_class in MODEL_CLASSES:\n",
    "        for split in range(KFOLD_SPLITS):\n",
    "            kfold_trainer = KfoldTrainer(\n",
    "                EXP_NAME, model_class, train_dataset, split, epochs=NUM_EPOCHS\n",
    "            )\n",
    "            kfold_trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ege_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
