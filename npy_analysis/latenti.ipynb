{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d23d7851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 14:40:39.313580: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-29 14:40:39.400391: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-29 14:40:39.400442: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-29 14:40:39.400496: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-29 14:40:39.413934: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-29 14:40:39.414816: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-29 14:40:40.845494: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loading waveform data from: /home/ege/rawcovar_data/2020-09-07_WEEK/processed_data/GAZK.npy\n",
      "Waveforms shape: (19968, 3000, 3)\n",
      "Loading labels from: /home/ege/rawcovar_data/2020-09-07_WEEK/processed_data/GAZK_y_condensed.npy\n",
      "Labels shape: (19968,)\n",
      "\n",
      "Data summary:\n",
      "Total samples: 19968\n",
      "Earthquake samples: 114\n",
      "Noise samples: 19854\n",
      "\n",
      "Extracting features from trained model...\n",
      "Loading model weights from: /home/ege/rawcovar/experiments/JUNE2025/29JUNE2025/1DAY_CONTINUOUS_EXP_2_2020-09/models/GAZK_representation_multiple_5epochs.h5\n",
      "Using model: RepresentationLearningSingleAutoencoder\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Layer count mismatch when loading weights from file. Model expected 2 layers, found 10 saved layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 406\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m feature_maps\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# Option 1: Run the full analysis\u001b[39;00m\n\u001b[0;32m--> 406\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;66;03m# Option 2: Just extract and save features\u001b[39;00m\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;66;03m# save_features_for_later()\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 242\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# Extract features from the trained model\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mExtracting features from trained model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 242\u001b[0m feature_maps \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features_from_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaveforms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMODEL_WEIGHTS_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMODEL_CLASS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# Generate visualizations\u001b[39;00m\n\u001b[1;32m    245\u001b[0m WAVEFORM_COLORS \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Colors for E, N, Z channels\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 104\u001b[0m, in \u001b[0;36mextract_features_from_model\u001b[0;34m(waveforms, model_weights_path, model_class)\u001b[0m\n\u001b[1;32m    101\u001b[0m _ \u001b[38;5;241m=\u001b[39m model(dummy_input)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Load the trained weights\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_weights_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessfully loaded weights!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Extract features\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/RAWCOVAR/lib/python3.10/site-packages/keras-2.14.0-py3.10.egg/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/RAWCOVAR/lib/python3.10/site-packages/keras-2.14.0-py3.10.egg/keras/src/saving/legacy/hdf5_format.py:819\u001b[0m, in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, model)\u001b[0m\n\u001b[1;32m    817\u001b[0m layer_names \u001b[38;5;241m=\u001b[39m filtered_layer_names\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(layer_names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(filtered_layers):\n\u001b[0;32m--> 819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer count mismatch when loading weights from file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(filtered_layers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m layers, found \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(layer_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m saved layers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    823\u001b[0m     )\n\u001b[1;32m    825\u001b[0m \u001b[38;5;66;03m# We batch weight value assignments in a single backend call\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;66;03m# which provides a speedup in TensorFlow.\u001b[39;00m\n\u001b[1;32m    827\u001b[0m weight_value_tuples \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mValueError\u001b[0m: Layer count mismatch when loading weights from file. Model expected 2 layers, found 10 saved layers."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from itertools import combinations\n",
    "import os\n",
    "from seismic_purifier import (\n",
    "    RepresentationLearningSingleAutoencoder, \n",
    "    RepresentationLearningDenoisingSingleAutoencoder, \n",
    "    RepresentationLearningMultipleAutoencoder\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Configuration\n",
    "# -------------------------------\n",
    "\n",
    "# Number of samples to plot\n",
    "NUM_SAMPLES = 10\n",
    "\n",
    "# Data paths - MODIFY THESE TO YOUR .npy FILES\n",
    "WAVEFORM_DATA_PATH = \"/home/ege/rawcovar_data/2020-09-07_WEEK/processed_data/GAZK.npy\"\n",
    "LABELS_DATA_PATH = \"/home/ege/rawcovar_data/2020-09-07_WEEK/processed_data/GAZK_y_condensed.npy\"\n",
    "\n",
    "# Model configuration - MODIFY THESE\n",
    "MODEL_WEIGHTS_PATH = \"/home/ege/rawcovar/experiments/JUNE2025/29JUNE2025/1DAY_CONTINUOUS_EXP_2_2020-09/models/GAZK_representation_multiple_5epochs.h5\"\n",
    "MODEL_CLASS = RepresentationLearningSingleAutoencoder  # Choose from:\n",
    "# - RepresentationLearningSingleAutoencoder\n",
    "# - RepresentationLearningDenoisingSingleAutoencoder  \n",
    "# - RepresentationLearningMultipleAutoencoder\n",
    "\n",
    "# -------------------------------\n",
    "# Core Functions\n",
    "# -------------------------------\n",
    "\n",
    "def compute_covariance(data_arrays):\n",
    "    \"\"\"\n",
    "    Computes autocovariance or cross-covariance between signals.\n",
    "    \n",
    "    Args:\n",
    "        data_arrays (np.ndarray): Variable number of 2D arrays, each with shape (timesteps, channels)\n",
    "    \n",
    "    Returns:\n",
    "        lags (np.ndarray): Lag values\n",
    "        avg_cov (np.ndarray): Averaged covariance\n",
    "    \"\"\"\n",
    "    if len(np.shape(data_arrays)) == 2:\n",
    "        data_arrays = np.expand_dims(data_arrays, axis=0)\n",
    "    \n",
    "    num_signals = len(data_arrays)    \n",
    "    num_timesteps, num_channels = data_arrays[0].shape\n",
    "\n",
    "    covariances = []\n",
    "    lags = np.arange(-num_timesteps + 1, num_timesteps)\n",
    "\n",
    "    if num_signals == 1:\n",
    "        # Autocovariance\n",
    "        data = data_arrays[0]\n",
    "        for c in range(num_channels):\n",
    "            channel_data = data[:, c]\n",
    "            channel_data = channel_data - np.mean(channel_data)  # Zero-mean\n",
    "            cov = np.correlate(channel_data, channel_data, mode='full')\n",
    "            covariances.append(cov)\n",
    "    else:\n",
    "        # Cross-covariance between all possible pairs\n",
    "        pairs = list(combinations(range(num_signals), 2))\n",
    "        for idx1, idx2 in pairs:\n",
    "            data1 = data_arrays[idx1]\n",
    "            data2 = data_arrays[idx2]\n",
    "            for c in range(num_channels):\n",
    "                channel_data1 = data1[:, c]\n",
    "                channel_data2 = data2[:, c]\n",
    "                channel_data1 = channel_data1 - np.mean(channel_data1)  # Zero-mean\n",
    "                channel_data2 = channel_data2 - np.mean(channel_data2)  # Zero-mean\n",
    "                cov = np.correlate(channel_data1, channel_data2, mode='full')\n",
    "                covariances.append(cov)\n",
    "\n",
    "    covariances = np.array(covariances)\n",
    "    avg_cov = np.mean(covariances, axis=0)\n",
    "    return lags, avg_cov\n",
    "\n",
    "def extract_features_from_model(waveforms, model_weights_path, model_class):\n",
    "    \"\"\"\n",
    "    Load model weights and extract feature maps.\n",
    "    \n",
    "    Args:\n",
    "        waveforms (np.ndarray): Shape (n_samples, 3000, 3)\n",
    "        model_weights_path (str): Path to the .h5 weights file\n",
    "        model_class: The model class from seismic_purifier\n",
    "    \n",
    "    Returns:\n",
    "        feature_maps (np.ndarray): Extracted feature maps\n",
    "    \"\"\"\n",
    "    print(f\"Loading model weights from: {model_weights_path}\")\n",
    "    print(f\"Using model: {model_class.__name__}\")\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = model_class()\n",
    "    model.compile()\n",
    "    \n",
    "    # Initialize model with dummy data\n",
    "    dummy_input = np.random.normal(size=[1, 3000, 3])\n",
    "    _ = model(dummy_input)\n",
    "    \n",
    "    # Load the trained weights\n",
    "    model.load_weights(model_weights_path)\n",
    "    print(\"Successfully loaded weights!\")\n",
    "    \n",
    "    # Extract features\n",
    "    print(\"Extracting features from waveforms...\")\n",
    "    feature_maps_list = []\n",
    "    batch_size = 32\n",
    "    \n",
    "    for i in range(0, len(waveforms), batch_size):\n",
    "        end_idx = min(i + batch_size, len(waveforms))\n",
    "        batch = waveforms[i:end_idx]\n",
    "        \n",
    "        model_out = model(batch)\n",
    "        \n",
    "        if model_class == RepresentationLearningMultipleAutoencoder:\n",
    "            # Extract first 5 feature maps for multiple autoencoder\n",
    "            batch_features = list(model_out)[0:5]\n",
    "            batch_features = np.array(batch_features)\n",
    "            # Transpose to (batch_size, num_feature_maps, timesteps, features)\n",
    "            batch_features = np.transpose(batch_features, axes=[1, 0, 2, 3])\n",
    "        else:\n",
    "            # Extract first feature map for single/denoising autoencoder\n",
    "            batch_features = list(model_out)[0:1]\n",
    "            batch_features = np.array(batch_features)\n",
    "            # Transpose to (batch_size, num_feature_maps, timesteps, features)\n",
    "            batch_features = np.transpose(batch_features, axes=[1, 0, 2, 3])\n",
    "        \n",
    "        feature_maps_list.append(batch_features)\n",
    "        \n",
    "        if (i + batch_size) % (batch_size * 10) == 0:\n",
    "            print(f\"  Processed {i + batch_size}/{len(waveforms)} samples...\")\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    feature_maps = np.concatenate(feature_maps_list, axis=0)\n",
    "    print(f\"Extracted feature maps shape: {feature_maps.shape}\")\n",
    "    \n",
    "    return feature_maps\n",
    "\n",
    "def plot_waveform_channel(ax, timesteps, waveform, channel_idx, ylim_min=None, ylim_max=None, \n",
    "                         color='blue', show_xticks=True):\n",
    "    \"\"\"\n",
    "    Plots a single waveform channel on the given axes.\n",
    "    \"\"\"\n",
    "    channels = ['E', 'N', 'Z']\n",
    "    ax.plot(timesteps, waveform, color=color, linewidth=1)\n",
    "    if channel_idx == 0:\n",
    "        ax.set_title(\"Waveform\", fontsize=14, pad=5, fontweight='bold')\n",
    "    \n",
    "    # Add channel label\n",
    "    ax.set_ylabel(f'{channels[channel_idx]} Channel', fontsize=10)\n",
    "    \n",
    "    if ylim_min is not None and ylim_max is not None:\n",
    "        ax.set_ylim(ymin=ylim_min, ymax=ylim_max)\n",
    "    \n",
    "    ax.tick_params(axis='y', labelsize=10)\n",
    "    if show_xticks:\n",
    "        ax.set_xlabel('Timesteps', fontsize=12)\n",
    "        ax.tick_params(axis='x', labelsize=10)\n",
    "    else:\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    \n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "def plot_heatmap(ax, heatmap, vmin=None, vmax=None, title=None):\n",
    "    \"\"\"\n",
    "    Plots the heatmap on the given axes.\n",
    "    \"\"\"\n",
    "    if vmin is not None and vmax is not None:\n",
    "        cax = ax.imshow(heatmap, aspect='auto', cmap='magma', origin='lower', vmin=vmin, vmax=vmax)\n",
    "    else:\n",
    "        cax = ax.imshow(heatmap, aspect='auto', cmap='magma', origin='lower')\n",
    "        \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    ax.tick_params(axis='x', labelsize=10)\n",
    "    ax.tick_params(axis='y', labelsize=10)\n",
    "    ax.set_xlabel('Timesteps', fontsize=12)\n",
    "    ax.set_ylabel('Features', fontsize=12)\n",
    "    plt.colorbar(cax, ax=ax, orientation='vertical', fraction=0.046, pad=0.04)\n",
    "\n",
    "def plot_autocovariance(ax, lags, autocov, ylim_min=None, ylim_max=None, title=None, \n",
    "                       ylabel='Autocovariance'):\n",
    "    \"\"\"\n",
    "    Plots the autocovariance function on the given axes.\n",
    "    \"\"\"\n",
    "    if ylim_min is not None and ylim_max is not None:\n",
    "        ax.set_ylim(ymin=ylim_min, ymax=ylim_max)\n",
    "        \n",
    "    ax.plot(lags, autocov)\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    ax.tick_params(axis='x', labelsize=10)\n",
    "    ax.tick_params(axis='y', labelsize=10)\n",
    "    ax.set_xlabel('Lag', fontsize=12)\n",
    "    ax.set_ylabel(ylabel, fontsize=12)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Load waveform and label data from .npy files.\n",
    "    \n",
    "    Returns:\n",
    "        waveforms (np.ndarray): Shape (n_samples, 3000, 3)\n",
    "        labels (np.ndarray): Shape (n_samples,)\n",
    "    \"\"\"\n",
    "    print(f\"Loading waveform data from: {WAVEFORM_DATA_PATH}\")\n",
    "    waveforms = np.load(WAVEFORM_DATA_PATH)\n",
    "    print(f\"Waveforms shape: {waveforms.shape}\")\n",
    "    \n",
    "    print(f\"Loading labels from: {LABELS_DATA_PATH}\")\n",
    "    labels = np.load(LABELS_DATA_PATH)\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    \n",
    "    # Validate data shapes\n",
    "    assert len(waveforms.shape) == 3, f\"Waveforms should be 3D (samples, timesteps, channels), got shape {waveforms.shape}\"\n",
    "    assert waveforms.shape[1] == 3000, f\"Expected 3000 timesteps, got {waveforms.shape[1]}\"\n",
    "    assert waveforms.shape[2] == 3, f\"Expected 3 channels, got {waveforms.shape[2]}\"\n",
    "    assert len(labels.shape) == 1, f\"Labels should be 1D, got shape {labels.shape}\"\n",
    "    assert waveforms.shape[0] == labels.shape[0], f\"Number of waveforms ({waveforms.shape[0]}) != number of labels ({labels.shape[0]})\"\n",
    "    \n",
    "    print(f\"\\nData summary:\")\n",
    "    print(f\"Total samples: {len(waveforms)}\")\n",
    "    print(f\"Earthquake samples: {np.sum(labels > 0.5)}\")\n",
    "    print(f\"Noise samples: {np.sum(labels <= 0.5)}\")\n",
    "    \n",
    "    return waveforms, labels\n",
    "\n",
    "# -------------------------------\n",
    "# Main Execution\n",
    "# -------------------------------\n",
    "\n",
    "def main():\n",
    "    # Load data\n",
    "    print(\"Loading data...\")\n",
    "    waveforms, labels = load_data()\n",
    "    \n",
    "    # Extract features from the trained model\n",
    "    print(\"\\nExtracting features from trained model...\")\n",
    "    feature_maps = extract_features_from_model(waveforms, MODEL_WEIGHTS_PATH, MODEL_CLASS)\n",
    "    \n",
    "    # Generate visualizations\n",
    "    WAVEFORM_COLORS = ['blue', 'green', 'red']  # Colors for E, N, Z channels\n",
    "    \n",
    "    # Separate earthquake and noise indices\n",
    "    earthquake_indices = np.where(labels > 0.5)[0]\n",
    "    noise_indices = np.where(labels <= 0.5)[0]\n",
    "    \n",
    "    print(f\"\\nFound {len(earthquake_indices)} earthquake samples and {len(noise_indices)} noise samples\")\n",
    "    \n",
    "    # Ensure equal number of earthquake and noise samples\n",
    "    NUM_PLOTS = min(len(earthquake_indices), len(noise_indices), NUM_SAMPLES)\n",
    "    print(f\"Will generate {NUM_PLOTS} comparison plots\")\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = \"latent_space_plots\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Determine covariance title based on model type\n",
    "    if MODEL_CLASS == RepresentationLearningMultipleAutoencoder:\n",
    "        latent_covariance_title = 'Latent Representation\\nCross-covariance Function'\n",
    "        latent_covariance_ylabel = 'Mean Cross-covariance'\n",
    "    else:\n",
    "        latent_covariance_title = 'Latent Representation\\nAutocovariance Function'\n",
    "        latent_covariance_ylabel = 'Autocovariance'\n",
    "    \n",
    "    for plot_idx in range(NUM_PLOTS):\n",
    "        eq_idx = earthquake_indices[plot_idx]\n",
    "        noise_idx = noise_indices[plot_idx]\n",
    "        \n",
    "        print(f\"Generating plot {plot_idx + 1}/{NUM_PLOTS} (EQ idx: {eq_idx}, Noise idx: {noise_idx})\")\n",
    "        \n",
    "        # Extract earthquake data\n",
    "        eq_waveform = waveforms[eq_idx]\n",
    "        eq_feature_map = feature_maps[eq_idx]\n",
    "        lags_waveform_eq, autocov_waveform_eq = compute_covariance(eq_waveform)\n",
    "        lags_heatmap_eq, autocov_heatmap_eq = compute_covariance(eq_feature_map)\n",
    "        \n",
    "        # Extract noise data\n",
    "        noise_waveform = waveforms[noise_idx]\n",
    "        noise_feature_map = feature_maps[noise_idx]\n",
    "        lags_waveform_noise, autocov_waveform_noise = compute_covariance(noise_waveform)\n",
    "        lags_heatmap_noise, autocov_heatmap_noise = compute_covariance(noise_feature_map)\n",
    "        \n",
    "        # Create a figure with a 1x2 grid: left for earthquake, right for noise\n",
    "        fig = plt.figure(figsize=(20, 10))\n",
    "        main_gs = GridSpec(1, 2, figure=fig, wspace=0.3)\n",
    "        \n",
    "        # --- Earthquake Column ---\n",
    "        eq_gs = main_gs[0, 0].subgridspec(2, 2, wspace=0.3, hspace=0.4)\n",
    "        \n",
    "        # Top-Left: Waveform Channels\n",
    "        eq_waveform_gs = eq_gs[0, 0].subgridspec(eq_waveform.shape[1], 1, hspace=0.3)\n",
    "        timesteps_eq = np.arange(eq_waveform.shape[0])\n",
    "        \n",
    "        for channel in range(eq_waveform.shape[1]):\n",
    "            ax = fig.add_subplot(eq_waveform_gs[channel, 0])\n",
    "            show_xticks = (channel == eq_waveform.shape[1] - 1)\n",
    "            plot_waveform_channel(ax, timesteps_eq, eq_waveform[:, channel], channel, \n",
    "                                  color=WAVEFORM_COLORS[channel % len(WAVEFORM_COLORS)], \n",
    "                                  show_xticks=show_xticks)\n",
    "        \n",
    "        # Top-Right: Heatmap\n",
    "        ax_heatmap_eq = fig.add_subplot(eq_gs[0, 1])\n",
    "        plot_heatmap(ax_heatmap_eq, eq_feature_map[0].T, title=\"Latent Representation\")\n",
    "        \n",
    "        # Bottom-Left: Autocovariance of Waveform\n",
    "        ax_autocov_waveform_eq = fig.add_subplot(eq_gs[1, 0])\n",
    "        plot_autocovariance(ax_autocov_waveform_eq, lags_waveform_eq, autocov_waveform_eq, \n",
    "                            title='Waveform\\nAutocovariance Function')\n",
    "        \n",
    "        # Bottom-Right: Autocovariance of Heatmap\n",
    "        ax_autocov_heatmap_eq = fig.add_subplot(eq_gs[1, 1])\n",
    "        plot_autocovariance(ax_autocov_heatmap_eq, lags_heatmap_eq, autocov_heatmap_eq, \n",
    "                            title=latent_covariance_title,\n",
    "                            ylabel=latent_covariance_ylabel)\n",
    "        \n",
    "        # --- Noise Column ---\n",
    "        # Use earthquake feature map range for consistent scaling\n",
    "        feature_map_max = np.max(eq_feature_map[0])\n",
    "        feature_map_min = np.min(eq_feature_map[0])\n",
    "        \n",
    "        autocov_heatmap_max = np.max(autocov_heatmap_eq)\n",
    "        autocov_heatmap_min = np.min(autocov_heatmap_eq)\n",
    "        \n",
    "        noise_gs = main_gs[0, 1].subgridspec(2, 2, wspace=0.3, hspace=0.4)\n",
    "        \n",
    "        # Top-Left: Waveform Channels\n",
    "        noise_waveform_gs = noise_gs[0, 0].subgridspec(noise_waveform.shape[1], 1, hspace=0.3)\n",
    "        timesteps_noise = np.arange(noise_waveform.shape[0])\n",
    "        \n",
    "        for channel in range(noise_waveform.shape[1]):\n",
    "            ax = fig.add_subplot(noise_waveform_gs[channel, 0])\n",
    "            show_xticks = (channel == noise_waveform.shape[1] - 1)\n",
    "            plot_waveform_channel(ax, timesteps_noise, noise_waveform[:, channel], channel, \n",
    "                                  color=WAVEFORM_COLORS[channel % len(WAVEFORM_COLORS)], \n",
    "                                  show_xticks=show_xticks)\n",
    "        \n",
    "        # Top-Right: Heatmap (with consistent scaling)\n",
    "        ax_heatmap_noise = fig.add_subplot(noise_gs[0, 1])\n",
    "        plot_heatmap(ax_heatmap_noise, noise_feature_map[0].T, feature_map_min, feature_map_max, \n",
    "                     \"Latent Representation\")\n",
    "        \n",
    "        # Bottom-Left: Autocovariance of Waveform\n",
    "        ax_autocov_waveform_noise = fig.add_subplot(noise_gs[1, 0])\n",
    "        plot_autocovariance(ax_autocov_waveform_noise, \n",
    "                            lags_waveform_noise, \n",
    "                            autocov_waveform_noise, \n",
    "                            title='Waveform\\nAutocovariance Function')\n",
    "        \n",
    "        # Bottom-Right: Autocovariance of Heatmap (with consistent scaling)\n",
    "        ax_autocov_heatmap_noise = fig.add_subplot(noise_gs[1, 1])\n",
    "        plot_autocovariance(ax_autocov_heatmap_noise, \n",
    "                            lags_heatmap_noise, \n",
    "                            autocov_heatmap_noise,\n",
    "                            autocov_heatmap_min,\n",
    "                            autocov_heatmap_max,\n",
    "                            latent_covariance_title,\n",
    "                            latent_covariance_ylabel)\n",
    "        \n",
    "        # --- Add Column Titles ---\n",
    "        fig.text(0.30, 0.935, 'Earthquake Sample', ha='center', va='center', \n",
    "                 fontsize=20, fontweight='bold')\n",
    "        fig.text(0.725, 0.935, 'Noise Sample', ha='center', va='center', \n",
    "                 fontsize=20, fontweight='bold')\n",
    "        \n",
    "        # Adjust overall layout and save the figure\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.92])\n",
    "        \n",
    "        # Save with informative filename\n",
    "        filename = f\"{output_dir}/latent_plot_pair_{plot_idx + 1:03d}_eq{eq_idx}_noise{noise_idx}.png\"\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)  # Close the figure to free memory\n",
    "        \n",
    "        if (plot_idx + 1) % 5 == 0:\n",
    "            print(f\"  Saved {plot_idx + 1} plots so far...\")\n",
    "    \n",
    "    print(f\"\\nAll plots saved to '{output_dir}' directory!\")\n",
    "    print(f\"Generated {NUM_PLOTS} comparison plots.\")\n",
    "\n",
    "# -------------------------------\n",
    "# Alternative: Save features for later use\n",
    "# -------------------------------\n",
    "\n",
    "def save_features_for_later():\n",
    "    \"\"\"\n",
    "    Extract and save feature maps to a .npy file for future use.\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    waveforms, labels = load_data()\n",
    "    \n",
    "    # Extract features\n",
    "    feature_maps = extract_features_from_model(waveforms, MODEL_WEIGHTS_PATH, MODEL_CLASS)\n",
    "    \n",
    "    # Save to file\n",
    "    output_path = \"extracted_feature_maps.npy\"\n",
    "    np.save(output_path, feature_maps)\n",
    "    print(f\"Saved feature maps to: {output_path}\")\n",
    "    \n",
    "    return feature_maps\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Option 1: Run the full analysis\n",
    "    main()\n",
    "    \n",
    "    # Option 2: Just extract and save features\n",
    "    # save_features_for_later()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAWCOVAR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
