{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 00:56:54.485041: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-19 00:56:54.514668: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-19 00:56:54.514691: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-19 00:56:54.514708: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-19 00:56:54.520761: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "from seismic_purifier.config import BATCH_SIZE\n",
    "from seismic_purifier.representation_learning_models import (\n",
    "    RepresentationLearningSingleAutoencoder,\n",
    "    RepresentationLearningDenoisingSingleAutoencoder,\n",
    "    RepresentationLearningMultipleAutoencoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 1. Configuration\n",
    "# ============================\n",
    "\n",
    "# Paths to your data\n",
    "TRAIN_DATA_PATH = \"/home/ege/rawcovar/ADVT_SUBSET_NPY/./KO.ADVT..HHN__20190831T235957120000Z__20190902T000002810000Z_processed.npy\"#'data/X_train_1280sample.npy'  # Replace with your actual path\n",
    "TEST_DATA_PATH = 'data/X_test_1280sample.npy'  # Replace with your actual path\n",
    "TRAIN_LABEL_PATH = 'data/Y_train_1280sample.npy'  # Replace with your actual path\n",
    "TEST_LABEL_PATH = 'data/Y_test_1280sample.npy'  # Replace with your actual path\n",
    "\n",
    "# Directory to save checkpoints and the final model\n",
    "CHECKPOINT_DIR = 'checkpoints'\n",
    "MODEL_SAVE_PATH = 'checkpoints/representation_cross_covariances.h5'\n",
    "\n",
    "# Training parameters\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (8640, 3000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Ensure directories exist\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(MODEL_SAVE_PATH), exist_ok=True)\n",
    "\n",
    "# ============================\n",
    "# 2. Data loading\n",
    "# ============================\n",
    "X_train = np.load(TRAIN_DATA_PATH)  # Expected shape: (num_samples, 3000, 3)\n",
    "print(f\"Training data shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 00:57:01.095304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22286 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:19:00.0, compute capability: 8.6\n",
      "2025-03-19 00:57:01.096367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22286 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1a:00.0, compute capability: 8.6\n",
      "2025-03-19 00:57:01.097269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 20267 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:67:00.0, compute capability: 8.6\n",
      "2025-03-19 00:57:01.098195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 22270 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 3. Representation Learning Model Instantiation\n",
    "# ============================\n",
    "\n",
    "# Choose the model you want to train\n",
    "# For example, using RepresentationLearningSingleAutoencoder\n",
    "#model = RepresentationLearningSingleAutoencoder(\n",
    "#    name=\"rep_learning_autoencoder\"\n",
    "#)\n",
    "\n",
    "# Alternatively, you can choose other models:\n",
    "# model = RepresentationLearningDenoisingSingleAutoencoder(\n",
    "#     name=\"rep_learning_denoising_autoencoder\",\n",
    "#     input_noise_std=1e-6,\n",
    "#     denoising_noise_std=2e-1\n",
    "# )\n",
    "model = RepresentationLearningMultipleAutoencoder(\n",
    "     name=\"rep_learning_autoencoder_ensemble\",\n",
    "     input_noise_std=1e-6,\n",
    "     eps=1e-27\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rep_learning_autoencoder_ensemble'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 4. Model Compilation\n",
    "# ============================\n",
    "optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE) \n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 5. Callbacks Setup\n",
    "# ============================\n",
    "# Define callbacks for saving checkpoints, early stopping.\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(CHECKPOINT_DIR, 'autoencoder_epoch_{epoch:02d}.h5'),\n",
    "        save_weights_only=True,\n",
    "        save_freq='epoch',\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=2,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 00:59:00.573693: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-03-19 00:59:01.750725: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2025-03-19 00:59:02.296978: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-03-19 00:59:02.895814: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f88c800b520 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-03-19 00:59:02.895855: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2025-03-19 00:59:02.895867: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2025-03-19 00:59:02.895877: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2025-03-19 00:59:02.895886: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2025-03-19 00:59:02.911471: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-03-19 00:59:03.038775: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - ETA: 0s - loss: 2.4856\n",
      "Epoch 1: saving model to checkpoints/autoencoder_epoch_01.h5\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "34/34 [==============================] - 140s 546ms/step - loss: 2.4856\n",
      "Epoch 2/5\n",
      "34/34 [==============================] - ETA: 0s - loss: 2.2234\n",
      "Epoch 2: saving model to checkpoints/autoencoder_epoch_02.h5\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "34/34 [==============================] - 14s 418ms/step - loss: 2.2234\n",
      "Epoch 3/5\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.9848\n",
      "Epoch 3: saving model to checkpoints/autoencoder_epoch_03.h5\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "34/34 [==============================] - 15s 434ms/step - loss: 1.9848\n",
      "Epoch 4/5\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.7839\n",
      "Epoch 4: saving model to checkpoints/autoencoder_epoch_04.h5\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "34/34 [==============================] - 15s 433ms/step - loss: 1.7839\n",
      "Epoch 5/5\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.6541\n",
      "Epoch 5: saving model to checkpoints/autoencoder_epoch_05.h5\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "34/34 [==============================] - 15s 431ms/step - loss: 1.6541\n",
      "Model saved to checkpoints/representation_cross_covariances.h5\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 6. Training the Representation Learning Model and Save.\n",
    "# ============================\n",
    "fit_result = model.fit(X_train, \n",
    "                       epochs=EPOCHS, \n",
    "                       batch_size=BATCH_SIZE, \n",
    "                       callbacks=callbacks, \n",
    "                       shuffle=False)\n",
    "\n",
    "model.save_weights(MODEL_SAVE_PATH)\n",
    "print(f\"Model saved to {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ege_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
