{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-15 15:02:44.211843: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-15 15:02:44.263728: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-15 15:02:44.263765: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-15 15:02:44.263801: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-15 15:02:44.272693: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-15 15:02:44.273164: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-15 15:02:45.464670: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "from seismic_purifier.config import BATCH_SIZE\n",
    "from seismic_purifier.representation_learning_models import (\n",
    "    RepresentationLearningSingleAutoencoder,\n",
    "    RepresentationLearningDenoisingSingleAutoencoder,\n",
    "    RepresentationLearningMultipleAutoencoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 1. Configuration\n",
    "# ============================\n",
    "\n",
    "# Paths to your data\n",
    "TRAIN_DATA_PATH = \"/home/ege/rawcovar_data/processed_data/KO.GAZK.20200908_235818.npy\"\n",
    "\n",
    "# Directory to save checkpoints and the final model\n",
    "CHECKPOINT_DIR = 'checkpoints'\n",
    "MODEL_SAVE_PATH = 'checkpoints/KO.GAZK_20200909_representation_single_20epochs.h5'\n",
    "\n",
    "# Training parameters\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (692, 3000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Ensure directories exist\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(MODEL_SAVE_PATH), exist_ok=True)\n",
    "\n",
    "# ============================\n",
    "# 2. Data loading\n",
    "# ============================\n",
    "X_train = np.load(TRAIN_DATA_PATH)  # Expected shape: (num_samples, 3000, 3)\n",
    "print(f\"Training data shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.any(np.isnan(X_train)))\n",
    "np.isnan(X_train).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 3. Representation Learning Model Instantiation\n",
    "# ============================\n",
    "\n",
    "# Choose the model you want to train\n",
    "# For example, using RepresentationLearningSingleAutoencoder\n",
    "model = RepresentationLearningSingleAutoencoder(\n",
    "    name=\"rep_learning_autoencoder\"\n",
    ")\n",
    "\n",
    "# Alternatively, you can choose other models:\n",
    "#model = RepresentationLearningDenoisingSingleAutoencoder(\n",
    " #    name=\"rep_learning_denoising_autoencoder\",\n",
    "  #   input_noise_std=1e-6,\n",
    "   #  denoising_noise_std=2e-1\n",
    " #)\n",
    "#model = RepresentationLearningMultipleAutoencoder(\n",
    " #    name=\"rep_learning_autoencoder_ensemble\",\n",
    "  #   input_noise_std=1e-6,\n",
    "   #  eps=1e-27\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rep_learning_autoencoder'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 4. Model Compilation\n",
    "# ============================\n",
    "optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE) \n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 5. Callbacks Setup\n",
    "# ============================\n",
    "# Define callbacks for saving checkpoints, early stopping.\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(CHECKPOINT_DIR, 'autoencoder_epoch_{epoch:02d}.h5'),\n",
    "        save_weights_only=True,\n",
    "        save_freq='epoch',\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='loss',\n",
    "        patience=2,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.2772 \n",
      "Epoch 1: saving model to checkpoints/autoencoder_epoch_01.h5\n",
      "3/3 [==============================] - 37s 2s/step - loss: 1.2772\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.1448\n",
      "Epoch 2: saving model to checkpoints/autoencoder_epoch_02.h5\n",
      "3/3 [==============================] - 5s 2s/step - loss: 1.1448\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.0528\n",
      "Epoch 3: saving model to checkpoints/autoencoder_epoch_03.h5\n",
      "3/3 [==============================] - 5s 1s/step - loss: 1.0528\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.9752\n",
      "Epoch 4: saving model to checkpoints/autoencoder_epoch_04.h5\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.9752\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.9520\n",
      "Epoch 5: saving model to checkpoints/autoencoder_epoch_05.h5\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.9520\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.9186\n",
      "Epoch 6: saving model to checkpoints/autoencoder_epoch_06.h5\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.9186\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.8909\n",
      "Epoch 7: saving model to checkpoints/autoencoder_epoch_07.h5\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.8909\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.8629\n",
      "Epoch 8: saving model to checkpoints/autoencoder_epoch_08.h5\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.8629\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.8385\n",
      "Epoch 9: saving model to checkpoints/autoencoder_epoch_09.h5\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.8385\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.8167\n",
      "Epoch 10: saving model to checkpoints/autoencoder_epoch_10.h5\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.8167\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.7996\n",
      "Epoch 11: saving model to checkpoints/autoencoder_epoch_11.h5\n",
      "3/3 [==============================] - 5s 1s/step - loss: 0.7996\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.7834\n",
      "Epoch 12: saving model to checkpoints/autoencoder_epoch_12.h5\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.7834\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.7695\n",
      "Epoch 13: saving model to checkpoints/autoencoder_epoch_13.h5\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.7695\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.7577\n",
      "Epoch 14: saving model to checkpoints/autoencoder_epoch_14.h5\n",
      "3/3 [==============================] - 5s 1s/step - loss: 0.7577\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.7471\n",
      "Epoch 15: saving model to checkpoints/autoencoder_epoch_15.h5\n",
      "3/3 [==============================] - 5s 1s/step - loss: 0.7471\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.7370\n",
      "Epoch 16: saving model to checkpoints/autoencoder_epoch_16.h5\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.7370\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.7276\n",
      "Epoch 17: saving model to checkpoints/autoencoder_epoch_17.h5\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.7276\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.7191\n",
      "Epoch 18: saving model to checkpoints/autoencoder_epoch_18.h5\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.7191\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.7114\n",
      "Epoch 19: saving model to checkpoints/autoencoder_epoch_19.h5\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.7114\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.7040\n",
      "Epoch 20: saving model to checkpoints/autoencoder_epoch_20.h5\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.7040\n",
      "Model saved to checkpoints/KO.GAZK_20200909_representation_single_10epochs.h5\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 6. Training the Representation Learning Model and Save.\n",
    "# ============================\n",
    "fit_result = model.fit(X_train, \n",
    "                       epochs=EPOCHS, \n",
    "                       batch_size=BATCH_SIZE, \n",
    "                       callbacks=callbacks, \n",
    "                       shuffle=False)\n",
    "\n",
    "model.save_weights(MODEL_SAVE_PATH)\n",
    "print(f\"Model saved to {MODEL_SAVE_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAWCOVAR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
