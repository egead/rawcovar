{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 03:30:36.618070: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-03 03:30:36.862757: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-03 03:30:36.862805: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-03 03:30:36.864116: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-03 03:30:36.971957: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-03 03:30:36.973633: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-03 03:30:39.017954: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "from seismic_purifier.config import BATCH_SIZE\n",
    "from seismic_purifier.representation_learning_models import (\n",
    "    RepresentationLearningSingleAutoencoder,\n",
    "    RepresentationLearningDenoisingSingleAutoencoder,\n",
    "    RepresentationLearningMultipleAutoencoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 1. Configuration\n",
    "# ============================\n",
    "\n",
    "# Paths to your data\n",
    "TRAIN_DATA_PATH = \"/home/ege/Documents/STEAD_SUBSAMPLER/SLVR_NPY/KO.SLVT.2019-09-24T00:00:00.000000Z-2019-09-29T00:00:00.080000Z.npy\"\n",
    "TRAIN_LABEL_PATH = 'data/Y_train_1280sample.npy'  # Replace with your actual path\n",
    "TEST_LABEL_PATH = 'data/Y_test_1280sample.npy'  # Replace with your actual path\n",
    "\n",
    "# Directory to save checkpoints and the final model\n",
    "CHECKPOINT_DIR = 'checkpoints'\n",
    "MODEL_SAVE_PATH = 'checkpoints/SLVT_FULL_representation_cross_covariances_20epochs.h5'\n",
    "\n",
    "# Training parameters\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (14400, 3000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Ensure directories exist\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(MODEL_SAVE_PATH), exist_ok=True)\n",
    "\n",
    "# ============================\n",
    "# 2. Data loading\n",
    "# ============================\n",
    "X_train = np.load(TRAIN_DATA_PATH)  # Expected shape: (num_samples, 3000, 3)\n",
    "print(f\"Training data shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.any(np.isnan(X_train)))\n",
    "np.isnan(X_train).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 3. Representation Learning Model Instantiation\n",
    "# ============================\n",
    "\n",
    "# Choose the model you want to train\n",
    "# For example, using RepresentationLearningSingleAutoencoder\n",
    "#model = RepresentationLearningSingleAutoencoder(\n",
    "#    name=\"rep_learning_autoencoder\"\n",
    "#)\n",
    "\n",
    "# Alternatively, you can choose other models:\n",
    "# model = RepresentationLearningDenoisingSingleAutoencoder(\n",
    "#     name=\"rep_learning_denoising_autoencoder\",\n",
    "#     input_noise_std=1e-6,\n",
    "#     denoising_noise_std=2e-1\n",
    "# )\n",
    "model = RepresentationLearningMultipleAutoencoder(\n",
    "     name=\"rep_learning_autoencoder_ensemble\",\n",
    "     input_noise_std=1e-6,\n",
    "     eps=1e-27\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rep_learning_autoencoder_ensemble'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 4. Model Compilation\n",
    "# ============================\n",
    "optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE) \n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 5. Callbacks Setup\n",
    "# ============================\n",
    "# Define callbacks for saving checkpoints, early stopping.\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(CHECKPOINT_DIR, 'autoencoder_epoch_{epoch:02d}.h5'),\n",
    "        save_weights_only=True,\n",
    "        save_freq='epoch',\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=2,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.3096\n",
      "Epoch 1: saving model to checkpoints/autoencoder_epoch_01.h5\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "57/57 [==============================] - 700s 9s/step - loss: 2.3096\n",
      "Epoch 2/5\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.7966\n",
      "Epoch 2: saving model to checkpoints/autoencoder_epoch_02.h5\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "57/57 [==============================] - 507s 9s/step - loss: 1.7966\n",
      "Epoch 3/5\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.5062\n",
      "Epoch 3: saving model to checkpoints/autoencoder_epoch_03.h5\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "57/57 [==============================] - 492s 9s/step - loss: 1.5062\n",
      "Epoch 4/5\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.3458\n",
      "Epoch 4: saving model to checkpoints/autoencoder_epoch_04.h5\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "57/57 [==============================] - 486s 9s/step - loss: 1.3458\n",
      "Epoch 5/5\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.2501\n",
      "Epoch 5: saving model to checkpoints/autoencoder_epoch_05.h5\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "57/57 [==============================] - 494s 9s/step - loss: 1.2501\n",
      "Model saved to checkpoints/SLVT_FULL_representation_cross_covariances_5epochs.h5\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 6. Training the Representation Learning Model and Save.\n",
    "# ============================\n",
    "fit_result = model.fit(X_train, \n",
    "                       epochs=EPOCHS, \n",
    "                       batch_size=BATCH_SIZE, \n",
    "                       callbacks=callbacks, \n",
    "                       shuffle=False)\n",
    "\n",
    "model.save_weights(MODEL_SAVE_PATH)\n",
    "print(f\"Model saved to {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAWCOVAR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
